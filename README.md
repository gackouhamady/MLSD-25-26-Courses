<!-- Badges: Program, Institution, Domains, Objectives, Tech Stack, Trends -->
<p align="center">
  <img alt="MLSD" src="https://img.shields.io/badge/Master-MLSD%2025--26-1E88E5?style=for-the-badge&logo=googlescholar&logoColor=white">
  <img alt="University" src="https://img.shields.io/badge/Université Paris Cité%20-6f42c1?style=for-the-badge&logo=academia&logoColor=white">
  <img alt="Location" src="https://img.shields.io/badge/Location-Paris%20(Europe%2FParis)-FF7043?style=for-the-badge&logo=googlemaps&logoColor=white">
</p>

<p align="center">
  <img alt="Domain: Data Engineering" src="https://img.shields.io/badge/Domain-Data%20Engineering-1976D2?style=for-the-badge">
  <img alt="Domain: Machine Learning" src="https://img.shields.io/badge/Domain-Machine%20Learning-388E3C?style=for-the-badge">
  <img alt="Domain: Deep Learning" src="https://img.shields.io/badge/Domain-Deep%20Learning-512DA8?style=for-the-badge">
  <img alt="Domain: NLP" src="https://img.shields.io/badge/Domain-NLP-00796B?style=for-the-badge">
  <img alt="Domain: RL" src="https://img.shields.io/badge/Domain-RL-455A64?style=for-the-badge">
  <img alt="Domain: Graph ML" src="https://img.shields.io/badge/Domain-Graph%20ML-5D4037?style=for-the-badge">
  <img alt="Domain: Time Series" src="https://img.shields.io/badge/Domain-Time%20Series-1976D2?style=for-the-badge">
</p>

<p align="center">
  <img alt="Objective: PhD (Academic)" src="https://img.shields.io/badge/Objective-PhD%20(Academic)-2E7D32?style=for-the-badge&logo=googlescholar&logoColor=white">
  <img alt="Objective: CIFRE" src="https://img.shields.io/badge/Objective-CIFRE-0077B6?style=for-the-badge">
  <img alt="Objective: R%26D" src="https://img.shields.io/badge/Objective-R%26D-1B5E20?style=for-the-badge">
</p>

<p align="center">
  <img alt="Python" src="https://img.shields.io/badge/Python-3.10%2B-3776AB?style=for-the-badge&logo=python&logoColor=white">
  <img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white">
  <img alt="Transformers" src="https://img.shields.io/badge/HF-Transformers-FFB000?style=for-the-badge&logo=huggingface&logoColor=black">
  <img alt="scikit-learn" src="https://img.shields.io/badge/scikit--learn-FF9800?style=for-the-badge&logo=scikitlearn&logoColor=white">
  <img alt="XGBoost" src="https://img.shields.io/badge/XGBoost-%20-0A66C2?style=for-the-badge">
  <img alt="LightGBM" src="https://img.shields.io/badge/LightGBM-%20-00C853?style=for-the-badge">
  <img alt="CatBoost" src="https://img.shields.io/badge/CatBoost-%20-212121?style=for-the-badge">
  <img alt="Spark" src="https://img.shields.io/badge/Apache%20Spark-%20-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white">
  <img alt="Kafka" src="https://img.shields.io/badge/Apache%20Kafka-%20-231F20?style=for-the-badge&logo=apachekafka&logoColor=white">
  <img alt="Airflow" src="https://img.shields.io/badge/Apache%20Airflow-%20-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white">
  <img alt="dbt" src="https://img.shields.io/badge/dbt-Core-FF694B?style=for-the-badge&logo=dbt&logoColor=white">
  <img alt="Delta Lake" src="https://img.shields.io/badge/Delta%20Lake-%20-43A047?style=for-the-badge">
  <img alt="Docker" src="https://img.shields.io/badge/Docker-%20-2496ED?style=for-the-badge&logo=docker&logoColor=white">
  <img alt="GitHub Actions" src="https://img.shields.io/badge/GitHub%20Actions-%20-2088FF?style=for-the-badge&logo=githubactions&logoColor=white">
  <img alt="MLflow" src="https://img.shields.io/badge/MLflow-%20-0194E2?style=for-the-badge&logo=mlflow&logoColor=white">
  <img alt="W&B" src="https://img.shields.io/badge/Weights%20%26%20Biases-%20-FFBE00?style=for-the-badge&logo=weightsandbiases&logoColor=black">
  <img alt="DVC" src="https://img.shields.io/badge/DVC-%20-945DD6?style=for-the-badge&logo=dvc&logoColor=white">
  <img alt="FAISS" src="https://img.shields.io/badge/FAISS-%20-263238?style=for-the-badge">
  <img alt="PyG" src="https://img.shields.io/badge/PyTorch%20Geometric-%20-E91E63?style=for-the-badge">
</p>

<p align="center">
  <img alt="Trend: RAG" src="https://img.shields.io/badge/Trend-RAG%20%F0%9F%94%AD-1565C0?style=for-the-badge">
  <img alt="Trend: QLoRA" src="https://img.shields.io/badge/Trend-QLoRA%20%F0%9F%94%A5-9C27B0?style=for-the-badge">
  <img alt="Trend: DPO" src="https://img.shields.io/badge/Trend-DPO-6A1B9A?style=for-the-badge">
  <img alt="Trend: Graph%20Transformers" src="https://img.shields.io/badge/Trend-Graph%20Transformers-455A64?style=for-the-badge">
  <img alt="Trend: UMAP" src="https://img.shields.io/badge/Trend-UMAP-00897B?style=for-the-badge">
  <img alt="Trend: vLLM" src="https://img.shields.io/badge/Trend-vLLM-37474F?style=for-the-badge">
</p>

# MLSD 25–26 — Courses

**Attendance is mandatory, including all PROJECT (PPD) sessions.**  
**Cohort induction:** 29/09/2024 (Rooms: Lavoisier A / Gley)

This repository centralizes notes, resources, and code for all modules in the MLSD program. It mirrors the official timetable (Oct 2024 → Mar 2025 teaching/PPD blocks, defenses in Jun & Sep 2025), and links directly to each UE directory below.

> Times shown are local (Paris): **Morning 09:00–12:30** · **Afternoon 14:00–17:30**.  
> Some days include **extended slots 16:30–18:30** (noted explicitly below).

---

## Repository Structure

- [`01-Data-Engineering`](./01-Data-Engineering/) — Data preprocessing, BI/Big Data Analytics, Packaging  
- [`02-Unsupervised-Learning`](./02-Unsupervised-Learning/) — Clustering, Mixture Models (LBM/EM/VB), Dimensionality Reduction, Factorization & Recommendation  
- [`03-Supervised-RL-TimeSeries`](./03-Supervised-RL-TimeSeries/) — Supervised Learning, Reinforcement Learning, Time Series, Evaluation Metrics  
- [`04-DeepLearning-Graph`](./04-DeepLearning-Graph/) — Deep Learning II, Data Embedding & Learning (DEL), Graph Learning, Advanced Topics  
- [`05-NLP-GenerativeAI`](./05-NLP-GenerativeAI/) — Generative AI, Core NLP techniques, Applications (chatbots, low-resource NLP)  
- [`06-PROJET-MLSD`](./06-PROJET-MLSD/) — MLSD Project (specs, plan, deliverables, code, references)  
- [`07-EXAMS-PREP`](./07-EXAMS-PREP/) — Past exams, revision sheets, oral preparation  
- [`08-RESOURCES-GLOBAL`](./08-RESOURCES-GLOBAL/) — Cross-cutting resources (math/stats/optim, Python ML stack, reading list, links)

Rooms used throughout: **Lavoisier A** and **Gley**.

---

## Key Dates (At a Glance)

- **Induction:** 29 Sep 2024 (Lavoisier A / Gley)  
- **Teaching Blocks:**  
  - **Oct–Dec 2024:** Core lectures & labs across UEs  
  - **Jan–Feb 2025:** RL, Mixture Models, Packaging, Exams & PPD/Soutenance preparations  
  - **Mar 2025:** PPD mandatory presence & Soutenances-PPD (26–27 Mar)
- **Internships:** Apr–May 2025 (in companies) — departures indicated after mid-Feb
- **Defenses (FA):** 22–25 Jun 2025  
- **FA Jury:** 04 Sep 2025  
- **Defenses (FI):** 14–18 Sep 2025  
- **FI Jury (Global end date):** **22 Sep 2025**

---

## Exams (Summary)

- **Dimensionality Reduction / DEL (Exam):** 07 Nov 2024 (afternoon)  
- **Supervised Learning (Exam L.L):** 28 Nov 2024 (morning)  
- **Deep Learning (Exam L.L):** 28 Nov 2024 (afternoon)  
- **Big Data (Exam S.M):** 17 Dec 2024 (morning)  
- **Generative AI (Exam S.M):** 17 Dec 2024 (afternoon)  
- **Mixture Models (Exam M.N):** 04 Feb 2025 (morning)  
- **Packaging (Exam S.M):** 04 Feb 2025 (afternoon)  
- **Reinforcement Learning (Exam B.B):** 10 Feb 2025 (afternoon)  
- **Other Exam:** 12 Feb 2025 (afternoon)

> **PPD / Soutenances-PPD:**  
> - PPD mandatory presence across early–mid March 2025  
> - Soutenances-PPD: 26–27 Mar 2025

---

## Detailed Calendar

### October 2024
| Date | Morning (09:00–12:30) | Afternoon (14:00–17:30) | Room | UE / ECUE |
|---|---|---|---|---|
| 01 Oct | Data preprocessing (A.F) | Data preprocessing (A.F) | Lavoisier A | Data Engineering |
| 02 Oct | BI (R) S.A* | BI (R) S.A* | Gley | Big Data Analytics |
| 03 Oct | Mathematics for ML (C.F) | Mathematics for ML (C.F) | Gley | Packaging |
| 08 Oct | Data preprocessing (A.F) | Data preprocessing (A.F) | Lavoisier A | Factorization & Recommendation |
| 09 Oct | Dimensionality Reduction II (M.N)* | Dimensionality Reduction II (M.N)* | Gley | Dimensionality Reduction |
| 10 Oct | Clustering (A. SAME)* | Clustering (A. SAME)* | Gley | Unsupervised Learning |
| 15 Oct | Clustering (A. SAME)* | Clustering (A. SAME)* | Lavoisier A | Time Series II |
| 16 Oct | Data Embedding & Learning — DEL (I.K) | DEL (I.K) | Gley | Deep Learning II |
| 17 Oct | Clustering (A. SAME)* | Clustering (A. SAME)* | Gley | Graph Learning |
| 22 Oct | Data Embedding & Learning — DEL (I.K) | DEL (I.K) | Lavoisier A | DEL |
| 23 Oct | Dimensionality Reduction II (M.N)* | Dimensionality Reduction II (M.N)* | Gley | — |
| 24 Oct | Dimensionality Reduction II (M.N)* | Dimensionality Reduction II (M.N)* | Gley | — |
| 29 Oct | Big Data (S.M)* | Big Data (S.M)* | Lavoisier A | — |
| 30 Oct | Big Data (S.M)* | Big Data (S.M)* | Gley | — |
| 31 Oct | Supervised Learning (L.L)* | Supervised Learning (14:00–16:15)* **+ Factorization & Recommendation (16:30–18:30)** | Gley | — |

### November 2024
| Date | Morning | Afternoon | Room | UE / ECUE |
|---|---|---|---|---|
| 05 Nov | Supervised Learning (L.L)* | Supervised Learning (L.L)* **+ Factorization & Recommendation (16:30–18:30)** | Lavoisier A | — |
| 06 Nov | Supervised Learning (L.L)* | Supervised Learning (L.L)* | Gley | — |
| 07 Nov | Data Embedding & Learning — DEL (I.K) | **Dimensionality Reduction / Data Embedding (Exam)** **+ Factorization & Recommendation (16:30–18:30)** | Gley | — |
| 12 Nov | Big Data (S.M)* | Big Data (S.M)* **+ Factorization & Recommendation (16:30–18:30)** | Lavoisier A | — |
| 13 Nov | Deep Learning II (B.H)* | Deep Learning II (B.H)* | Gley | — |
| 14 Nov | Deep Learning II (B.H)* | Deep Learning II (B.H)* | Gley | — |
| 19 Nov | Data Embedding & Learning — DEL (I.K) | Data Embedding & Learning — DEL (I.K) | Lavoisier A | — |
| 20 Nov | Deep Learning II (B.H)* | Deep Learning II (B.H)* | Gley | — |
| 21 Nov | Generative AI | Generative AI **+ Factorization & Recommendation (16:30–18:30)** | Gley | — |
| 26 Nov | Generative AI | Generative AI | Lavoisier A | — |
| 27 Nov | Graph Learning (S.A)* | Graph Learning (S.A)* | Gley | — |
| 28 Nov | **Supervised Learning (Exam L.L)** | **Deep Learning (Exam L.L)** | Gley | — |

### December 2024
| Date | Morning | Afternoon | Room | UE / ECUE |
|---|---|---|---|---|
| 03 Dec | Generative AI | Generative AI | Lavoisier A | — |
| 04 Dec | Graph Learning (S.A)* | Graph Learning (S.A)* | Gley | — |
| 05 Dec | Time Series | Time Series | Gley | — |
| 10 Dec | Generative AI | Generative AI | Lavoisier A | — |
| 11 Dec | Graph Learning (S.A)* | Graph Learning (S.A)* | Gley | — |
| 12 Dec | — | Time Series II | Gley | — |
| 17 Dec | **Big Data (Exam S.M)** | **Generative AI (Exam S.M)** | Lavoisier A | — |
| 18 Dec | — | — | Gley | — |
| 19 Dec | Time Series II | Time Series II | Gley | — |

### January 2025
| Date | Morning | Afternoon | Room | UE / ECUE |
|---|---|---|---|---|
| 07 Jan | Reinforcement Learning (B.B)* | Packaging (S.M) | Lavoisier A | — |
| 08 Jan | Reinforcement Learning (B.B)* | Packaging (S.M) | Gley | — |
| 09 Jan | Reinforcement Learning (B.B)* | **PROJECT — PPD** | Gley | — |
| 14 Jan | Reinforcement Learning (B.B)* | Mixture Models → LBM | Lavoisier A | — |
| 15 Jan | Reinforcement Learning (B.B)* | Mixture Models → LBM | Gley | — |
| 16 Jan | Reinforcement Learning (B.B)* | Mixture Models → LBM | Gley | — |
| 21 Jan | Mixture Models → LBM | Mixture Models → LBM | Lavoisier A | — |
| 22 Jan | Packaging (S.M) | Packaging (S.M) | Gley | — |
| 23 Jan | **PROJECT — mandatory presence** | **PROJECT — mandatory presence** | Gley | — |

### Late January – February 2025
| Date | Morning | Afternoon | Room | Notes |
|---|---|---|---|---|
| 28 Jan | Packaging (S.M) | Packaging (S.M) | Lavoisier A | — |
| 29 Jan | **PROJECT — mandatory presence** | **PROJECT — mandatory presence** | Gley | — |
| 30 Jan | **PROJECT — mandatory presence** | **PROJECT — mandatory presence** | Gley | — |
| 04 Feb | **Mixture Models (Exam M.N)** | **Packaging (Exam S.M)** | Lavoisier A | — |
| 05 Feb | MLSD FA (PPD) — MLSD FI (Soutenance PPD) | Same | Gley | — |
| 06 Feb | MLSD FA (PPD) — MLSD FI (Soutenance PPD) | Same | Gley | — |
| 10 Feb (Tue) | MLSD FA (PPD) — MLSD FI (Soutenance PPD) | **Exam (B.B)** | — | RL Exam |
| 11 Feb | MLSD FA (PPD) — MLSD FI (Soutenance PPD) | Same | Lavoisier A | — |
| 12 Feb | MLSD FA (PPD) — MLSD FI (Soutenance PPD) | **Exam (Other)** | Gley | — |
| 13 Feb | MLSD FA (PPD) — MLSD FI (Soutenance PPD) | Same | — | **Internship departures (MLSD-FI)** |

### March 2025 — PPD & Soutenances-PPD
| Date | Morning | Afternoon | Room |
|---|---|---|---|
| 05 Mar | MLSD FA (PPD) — mandatory presence | MLSD FA (PPD) — mandatory presence | Gley |
| 06 Mar | MLSD FA (PPD) — mandatory presence | MLSD FA (PPD) — mandatory presence | Gley |
| 12 Mar | MLSD FA (PPD) — mandatory presence | MLSD FA (PPD) — mandatory presence | Gley |
| 13 Mar | MLSD FA (PPD) — mandatory presence | MLSD FA (PPD) — mandatory presence | Gley |
| 19 Mar | MLSD FA (PPD) — mandatory presence | MLSD FA (PPD) — mandatory presence | Gley |
| 20 Mar | MLSD FA (PPD) — mandatory presence | MLSD FA (PPD) — mandatory presence | Gley |
| 26 Mar | **Soutenances-PPD** | **Soutenances-PPD** | Gley |
| 27 Mar | **Soutenances-PPD** | **Soutenances-PPD** | Gley |

### June & September 2025 — Final Defenses & Juries
- **FA Defenses:** 22–25 Jun 2025  
- **FA Jury:** 04 Sep 2025  
- **FI Defenses:** 14–18 Sep 2025  
- **FI Jury (Global end date):** **22 Sep 2025**

---

## UE Mapping (Folders ↔ Teaching Content)

- **01-Data-Engineering:** Data Preprocessing (A.F), BI / Big Data Analytics (R, S.A, S.M), Packaging (S.M)  
- **02-Unsupervised-Learning:** Clustering (A. SAME), Mixture Models (LBM/EM/VB), Dimensionality Reduction (M.N), Factorization & Recommendation  
- **03-Supervised-RL-TimeSeries:** Supervised Learning (L.L), Reinforcement Learning (B.B), Time Series (incl. TS II), Evaluation Metrics  
- **04-DeepLearning-Graph:** Deep Learning II (B.H), Data Embedding & Learning — DEL (I.K), Graph Learning (S.A), Advanced Topics  
- **05-NLP-GenerativeAI:** Generative AI, NLP techniques, Applications (chatbots, translation, low-resource NLP)  
- **06-PROJET-MLSD:** MLSD project (specs, plan, deliverables, code, references)  
- **07-EXAMS-PREP:** Exam preparation, past papers, cheat sheets, oral prep  
- **08-RESOURCES-GLOBAL:** Math/Stats/Optimization, Python ML stack, curated readings & links

---

## How to Use This Repository

1. Each UE folder contains:
   - `README.md` (module syllabus & objectives),  
   - `notes.md` (your synthesized notes),  
   - `resources.md` (papers, videos, libraries),  
   - `notebooks/` or `code/` for exercises and demos.
2. Use commit messages to track learning progress and exam prep.
3. Keep PPD artifacts in `06-PROJET-MLSD/` (plan, deliverables, references).

> **Disclaimer:** This README mirrors the plan you provided. If the school updates rooms, dates, or exam formats, reflect those changes here and in each UE’s `README.md`.

# MLSD 25–26 — Program Goals by UE
**Attendance is mandatory (including all PROJECT sessions).**  
**Scope:** This document summarizes the **strategic goals** and **learning outcomes** for every UE (teaching unit) in the Master. It states what a top student should aim to **know, build, and prove** by the end of each unit, with **evidence** suitable for academic, CIFRE, or R&D paths.

---

## Program-wide outcomes (what every graduate can do)
- **Design end-to-end ML systems**: data → modeling → evaluation → deployment, with **reproducibility** (seeds, configs, CI).
- **Choose methods** based on data regime & constraints; articulate **trade-offs** (accuracy, latency, cost, risk).
- **Evaluate properly**: leakage-safe splits, uncertainty (CIs, prediction intervals), and decision-oriented metrics.
- **Communicate to stakeholders**: concise executive summaries, risk/impact narratives, and decision cards (*when to use what*).

---

## UE 01 — Data Engineering
### Strategic objective (the “why”)
Make you **production-ready** for building reliable **batch & streaming** data pipelines and analytics layers that power ML & BI.

### Learning outcomes
- Build **lakehouse pipelines** (Kafka/CDC → Spark/Beam → Delta/Iceberg/Hudi/Parquet) with **schema/contract** control.
- Implement **data transformations** with dbt; enforce **data quality** (Great Expectations/Soda/Deequ) and **lineage** (OpenLineage/Marquez, DataHub).
- Package & ship code professionally: **pyproject.toml**, **Docker** multi-stage, **CI/CD** (GitHub Actions), **pre-commit** gates, type safety.

### Evidence of achievement
- One **Dockerized stack** (`docker compose up`) that ingests → validates → models → serves to a BI artifact (Shiny/Quarto/Power BI/Tableau).
- **Runbooks & contracts** (schemas, DQ checks), lineage views, and a **passing** CI pipeline.
- Short **post-mortem** on failure scenarios (late/dirty data) with the mitigation plan.

---

## UE 02 — Unsupervised Learning
### Strategic objective
Turn unlabeled data into **structure and insight** with rigor (stability, diagnostics) and **actionable** outputs (segments, maps, top-N).

### Learning outcomes
- Build **unsupervised pipelines**: preprocessing → representation (PCA/UMAP/… ) → clustering/factorization → evaluation → reporting.
- Choose and tune **K-Means/MBKMeans, GMM(EM), HDBSCAN/DBSCAN, Agglomerative, Spectral**; **NMF/SVD/ALS**, **Latent Block Models**.
- Evaluate with **internal metrics** (Silhouette, CH, DB), **stability** (bootstrap/consensus), and **external** (ARI/NMI when available).
- For recommendation: measure **Recall@K/MAP@K/NDCG@K** with **diversity** and **coverage**.

### Evidence of achievement
- Comparative study across **≥3 clustering families** on the **same embeddings** with **stability analysis**.
- **Manifold diagnostics** (trustworthiness/continuity) + parameter decision card (t-SNE/UMAP).
- Factorization/recsys experiment with **ranking metrics + error bars** and **diversity/coverage**.

---

## UE 03 — Supervised Learning, Reinforcement Learning & Time Series
### Strategic objective
Provide the **core toolkit** for applied AI: **reliable predictors**, **safe RL agents**, and **temporal models** with **business-ready** reporting.

### Learning outcomes
- **Supervised**: leakage-free pipelines; **calibrated** probabilities; **interpretability** (global/local); robust **HPO** (nested CV/Optuna).
- **RL**: design agents (PPO/SAC etc.), **environment abstraction**, **offline/online evaluation**, basic **safety constraints**.
- **Time series**: rolling **backtests**, hierarchical **reconciliation** (MinT), **probabilistic** forecasts (pinball loss), exogenous drivers.

### Evidence of achievement
- **Calibrated** tabular model with **threshold decision card** driven by business costs + SHAP report.
- RL agent with **seed-averaged curves**, **OPE (IPS/DR)** + CIs, and a short **safety** note (constraints/violations).
- Forecasting report with **rolling-origin** backtests, **prediction intervals**, and **reconciliation** improvements.

---

## UE 04 — Deep Learning & Graph Learning
### Strategic objective
Advance from “training models” to **engineering modern neural systems** (DL + Embeddings + GNNs) that **scale** and **generalize**—aligned with research (e.g., **Hybrid DialogueGCN**).

### Learning outcomes
- Implement and fine-tune **CNNs/RNNs/Transformers** with **mixed precision**, schedulers (One-Cycle/Cosine), regularization, and distributed training.
- Build **embedding pipelines** (contrastive/metric; text/audio/image) and evaluate for **retrieval** & downstream transfer.
- Design **GNNs** (GCN/GAT/GraphSAGE/R-GCN) and **Graph Transformers**, including **hetero/dynamic** graphs, with rigorous evaluation protocols.

### Evidence of achievement
- **Strong supervised baseline** (mean±CI over ≥5 seeds) with an **efficiency table** (latency, memory, throughput).
- Embedding → **ANN serving** (FAISS/HNSW/IVF-PQ) with **Recall@K/MRR/nDCG** and latency P95.
- Graph task (node/link/graph) with **leakage-safe** negatives, **Hits@K/MRR/AUC**, and **ablations** (oversmoothing fixes, temporal attention).

---

## UE 05 — NLP & Generative AI
### Strategic objective
Be able to **design, align, and serve** LLM-centric systems: **Prompting → RAG → PEFT (LoRA/QLoRA) → Alignment (DPO/RLHF)** with **guardrails** and solid evaluation.

### Learning outcomes
- Build **RAG** pipelines (chunking, retrieval, reranking), evaluate **EM/F1, nDCG**, and **hallucination** rates (ragas/TruLens).
- Fine-tune via **PEFT** (QLoRA), compare **zero-shot vs. SFT vs. RAG+SFT**, and report **confidence intervals**.
- Serve efficiently (vLLM/TGI), manage **quantization** and **prompt caching**; add **guardrails** for safety/format.

### Evidence of achievement
- API/demo: **RAG + PEFT** with **quality & latency** dashboards, guardrails enabled.
- **Ablations** & **decision cards** (which retrieval/embedding/reranker under which constraints).

---

## UE 06 — Projet Professionnel (PPD & Soutenances)
### Strategic objective
Transform your skills into a **portfolio-grade project** with **clear impact**, **clean engineering**, and **scholarly rigor**—ready for **recruiters** and **PhD committees**.

### Learning outcomes
- Frame a problem → design a **credible method** → gather **evidence** (metrics, CIs, ablations) → deliver **decision-oriented** outputs (demo, report).
- Manage the project like a professional: scope, milestones, risks, versioning, **reproducibility** (data/code), and **ethics**.

### Evidence of achievement
- **Repo** (tests, CI, seeds, configs) + **demo** (offline fallback).  
- **Executive summary** (problem → method → evidence → decision → risks) and **soutenance** with anticipated Q&A.
- If applicable: **tech report/poster** suitable for submission (workshop/demo).

---

## UE 07 — EXAMS-PREP (Past exams, revision sheets, oral prep)
### Strategic objective
Convert knowledge into **exam-ready mastery** and **confident orals** with **targeted drills** and **leakage-safe reasoning**.

### Learning outcomes
- Build **high-yield** sheets per UE (formulas, traps, minimal examples).  
- Practice **exam-style problems** under time; maintain an **error log**; rehearse **10-10-10** orals (talk/Q&A/debrief).

### Evidence of achievement
- Folder with **worked past papers**, **one-pagers**, **oral decks/poster**, **decision cards**, **exam-day protocol**.

---

## UE 08 — RESOURCES-GLOBAL (Math/Stats/Optim, Python ML stack, reading list)
### Strategic objective
Maintain a curated **knowledge base** that accelerates learning and supports **rigorous reasoning** across all UEs.

### Learning outcomes
- Keep **math/stats/optim** refreshers at hand; track **libraries & tools**; curate **reading lists** (papers, talks, tutorials).
- Document **patterns & anti-patterns** you reuse in projects/exams.

### Evidence of achievement
- Structured notes (definitions, lemmas you actually use), tiny **worked examples**, and **reference snippets** (code/CLI) you can paste into projects.

---

## Professional standards (applies to every UE)
- **Reproducibility**: deterministic seeds, config files, environment lock, CI checks.  
- **Honest evaluation**: leakage-safe splits; multiple seeds; **CIs**; reporting of **effect sizes**.  
- **Risk & ethics**: data governance, safety constraints, fairness considerations where relevant.  
- **Communication**: results **traceable** (tables/plots), **plain-language** summaries, and explicit **limitations**.

> **Bottom line:** A top MLSD student can **design**, **justify**, **evaluate**, and **communicate** advanced ML systems—bridging research-grade rigor and production-grade engineering.

